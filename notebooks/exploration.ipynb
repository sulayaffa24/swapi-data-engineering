{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sulayaffa/Desktop/Data Engineering/data engineering projects/star_wars_project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name rotation_period orbital_period diameter              climate  \\\n",
      "0  Tatooine              23            304    10465                 arid   \n",
      "1  Alderaan              24            364    12500            temperate   \n",
      "2  Yavin IV              24           4818    10200  temperate, tropical   \n",
      "3      Hoth              23            549     7200               frozen   \n",
      "4   Dagobah              23            341     8900                murky   \n",
      "\n",
      "        gravity                             terrain surface_water  population  \\\n",
      "0    1 standard                              desert             1      200000   \n",
      "1    1 standard               grasslands, mountains            40  2000000000   \n",
      "2    1 standard                 jungle, rainforests             8        1000   \n",
      "3  1.1 standard  tundra, ice caves, mountain ranges           100     unknown   \n",
      "4           N/A                      swamp, jungles             8     unknown   \n",
      "\n",
      "                                           residents  \\\n",
      "0  [Luke Skywalker, C-3PO, Darth Vader, Owen Lars...   \n",
      "1  [Leia Organa, Bail Prestor Organa, Raymus Anti...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                                               films  \\\n",
      "0  [A New Hope, Return of the Jedi, The Phantom M...   \n",
      "1                  [A New Hope, Revenge of the Sith]   \n",
      "2                                       [A New Hope]   \n",
      "3                          [The Empire Strikes Back]   \n",
      "4  [The Empire Strikes Back, Return of the Jedi, ...   \n",
      "\n",
      "                       created                       edited       url  \n",
      "0  2014-12-09T13:50:49.641000Z  2014-12-20T20:58:18.411000Z  Tatooine  \n",
      "1  2014-12-10T11:35:48.479000Z  2014-12-20T20:58:18.420000Z  Alderaan  \n",
      "2  2014-12-10T11:37:19.144000Z  2014-12-20T20:58:18.421000Z  Yavin IV  \n",
      "3  2014-12-10T11:39:13.934000Z  2014-12-20T20:58:18.423000Z      Hoth  \n",
      "4  2014-12-10T11:42:22.590000Z  2014-12-20T20:58:18.425000Z   Dagobah  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "# Simple cache for nested URLs to avoid repeated HTTP calls\n",
    "URL_CACHE = {}\n",
    "\n",
    "def get_data(url):\n",
    "    \"\"\"\n",
    "    This function fetches JSON data from the SWAPI\n",
    "    website. \n",
    "    \"\"\"\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_all_pages(url):\n",
    "    \"\"\"\n",
    "    Handles pagination - returns all `results` across pages\n",
    "    from the SWAPI\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    while url:\n",
    "        data = get_data(url)\n",
    "        \n",
    "        if isinstance(data, dict) and \"results\" in data:\n",
    "            results.extend(data[\"results\"])\n",
    "            url = data.get(\"next\")\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            results.extend(data)\n",
    "            url = None\n",
    "\n",
    "        elif isinstance(data, dict):\n",
    "            results.append(data)\n",
    "            url = None\n",
    "\n",
    "        else:\n",
    "            raise TypeError(f\"Unexpected response type from API {type(data)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def nested_urls(value):\n",
    "    \"\"\"\n",
    "    Handles nested API URLs\n",
    "    - If value is a list of URLs, fetch names or titles.\n",
    "    - If single URL, fetch and return name or title.\n",
    "    - Otherwise, return as is\n",
    "    \"\"\"\n",
    "\n",
    "    # List of URLs\n",
    "    if isinstance(value, list) and all(isinstance(v, str) and v.startswith(\"http\") for v in value):\n",
    "        names = []\n",
    "        for v in value:\n",
    "            names.append(_fetch_name_or_title(v))\n",
    "        return names\n",
    "\n",
    "    # Single URL\n",
    "    if isinstance(value, str) and value.startswith(\"http\"):\n",
    "        return _fetch_name_or_title(value)\n",
    "    \n",
    "    # Non-URL value \n",
    "    return value\n",
    "\n",
    "def _fetch_name_or_title(url):\n",
    "    \"\"\"\n",
    "    Fetches a URL and returns 'name' or 'title', using a cache\n",
    "    \"\"\"\n",
    "    if url in URL_CACHE:\n",
    "        return URL_CACHE[url]\n",
    "\n",
    "    try:\n",
    "        sub_data = get_data(url)\n",
    "        value = sub_data.get(\"name\") or sub_data.get(\"title\")\n",
    "    except Exception:\n",
    "        value = None\n",
    "\n",
    "    URL_CACHE[url] = value\n",
    "    return value\n",
    "\n",
    "\n",
    "def normalize_entity_data(entity_data):\n",
    "    \"\"\"\n",
    "    Replaces nested URLs in an entity's attributes with human-readble\n",
    "    names/titles\n",
    "    \"\"\"\n",
    "    normalized = []\n",
    "\n",
    "    for item in entity_data:\n",
    "        record = {}\n",
    "        for key, value in item.items():\n",
    "            record[key] = nested_urls(value)\n",
    "        normalized.append(record)\n",
    "    return normalized\n",
    "\n",
    "# URL Usage\n",
    "def get_normalized_planets(url: str = \"https://swapi.info/api/planets\"):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "    - fetch all planets\n",
    "    - normalize nested URLs\n",
    "    - return as a Pandas DataFrame\n",
    "    \"\"\"\n",
    "    raw_planets = get_all_pages(url)\n",
    "    normalized_planets = normalize_entity_data(raw_planets)\n",
    "    return pd.DataFrame(normalized_planets)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_planets =  get_normalized_planets()\n",
    "    print(df_planets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 64-bit ('3.11.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b08b87bfdf5b1cefc4a62d3dd075e77f6b21ba4e2ef4dc4972af85a13972e8fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
